{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STATISTICS Applied to data science\n",
    "\n",
    "## Exercises PART 1: Descriptive statistics\n",
    "\n",
    "Employing descriptive statistics is one of the main steps of the POC stage (proof of concept) and extremely helpful during model evaluation. In this notebook you'll find some common routines for descriptive statistics in Python, and exercises about data transformation and scaling. \n",
    "\n",
    "![Image](data_1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries and configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import random\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from statsmodels.stats import power\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (12, 20)\n",
    "%matplotlib inline\n",
    "\n",
    "from statsmodels.compat import lzip\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.stats.api as sms\n",
    "\n",
    "# jupyter lab configs\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1 - Your own summary statistics and descriptors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement code for the functions below. In each function, make sure you call the function written before. E.g., in `rmse()` use the values returned by `mse()`. The aim of this exercise is just to understand how these diferent metrics are related, and which aspect of the data they are representing.   \n",
    "\n",
    "**You can use the map below to see the relationships between metrics and then plan how to structure your functions** \n",
    "\n",
    "![Image](map.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_mean(x):\n",
    "    if len(x)>0:\n",
    "        return sum(x)/len(x)\n",
    "\n",
    "def my_sum_squares():\n",
    "    pass\n",
    "\n",
    "def my_mse():\n",
    "    # mean squared error\n",
    "    pass\n",
    "\n",
    "def my_rmse():\n",
    "    # rooted mean squared error\n",
    "    pass\n",
    "\n",
    "def my_variance():\n",
    "    pass\n",
    "\n",
    "def my_std_dev():\n",
    "    pass\n",
    "\n",
    "def my_std_error():\n",
    "    pass\n",
    "\n",
    "def my_confidence_95():\n",
    "    pass\n",
    "    \n",
    "def my_covariance():\n",
    "    pass\n",
    "\n",
    "def my_coeficient_variation():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make sure it works!! In Python use `assert`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = random.randint(500, size=(32))\n",
    "assert my_mean(x) == np.mean(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observe the properties of a Normal Distribution using cumulative probability plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.norm.cdf(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.norm.cdf(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.norm.cdf(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.norm.cdf(2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.norm.cdf(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the percentage of the curve lower than the mean minus 3 deviations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.norm.cdf(-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the percentage of the curve lower than the mean plus 2 sd?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.norm.cdf(-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the percentage of the curve ABOVE the mean plus 2 sd?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - stats.norm.cdf(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many samples should we expec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below plots the cumulative distribution given a certain mean and standard deviation. Then change the mean and std and see what happens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_cdf(mean=0.0, std=1.0):\n",
    "    # 50 numbers between -3σ and 3σ\n",
    "    x = np.linspace(-3*std, 3*std, 50)\n",
    "    # CDF at these values\n",
    "    y = stats.norm.cdf(x, loc=mean, scale=std)\n",
    "    plt.ylabel(\"Cumulative Probability\")\n",
    "    plt.title(\"Cum. Dist. for Gaussian of mean = {0} | std. dev. = {1}\".format(mean, std))\n",
    "    plt.plot(x,y, color=\"black\")\n",
    "    plt.xlabel(\"Variate\")\n",
    "    plt.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_cdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_cdf(mean=2, std=2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_cdf(mean=3, std=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data transformations\n",
    "\n",
    "## The most common procedures are *feature scaling* and *linearization*:\n",
    "\n",
    "1. `Scaling` means you transform the data so all quantitative features are, let's say, *speaking the same language*. We will apply `scaling` to the quantitative features. Min-max, z-score, mean normalization are very used. Particularly, I always use z-score, and this transformation is also the most common method employed in *unsupervised learning* suchs as PCA, clustering, etc.\n",
    "\n",
    "2. `Linearization` will be usually needed to transform the `target`, or `dependent` variable, i. e., what you are trying to model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature scaling (a.k.a. standardization, normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Z-score transformation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image](zscore.gif)\n",
    "You can use `scipy.stats.zscore()` or write your own function, which is way more fun:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_z_score(x):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with non-gaussian data \n",
    "\n",
    "There's usually three ways of carrying on the analysis if you are working with regression problems and quantitative **target** variables that are not normally-distributed.\n",
    "1. Look for models that don't need linear relationships in the data (E. g. random forests, boosted trees)\n",
    "2. Look for models that can handle different distributions, like Poisson or Binomial (a.k.a. Generalized Linear Models)\n",
    "3. If you are using a hypothesis test, use bootstrapping to generate to generate the null model \n",
    "4. Apply transformations (log, sqrt, box-cox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning**  \n",
    "\n",
    "Log-transformation is a common tool in statistics. However, there is a pitfall in using log transformation of your data. Especially if you have a wide range of numbers, keep in mind that log will \"compress\" the data significantly more, and this can prevent the identification of interesting patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# difference betwee the log and sqrt transformation of a \"big\" value\n",
    "np.sqrt(34565)\n",
    "np.log(34565)\n",
    "\n",
    "# difference betwee the log and sqrt transformation of a \"small\" value\n",
    "np.sqrt(107)\n",
    "np.log(107)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below plots the diagnostic plots **QQ Plots** for two sets of variables, like raw (unstransformed) and transformed data, for comparison. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_compare_transformations(raw_data, transformed_data, transformation_used):\n",
    "    fig = plt.figure()\n",
    "    ax1 = fig.add_subplot(211)\n",
    "    prob = stats.probplot(raw_data, dist=stats.norm, plot=ax1)\n",
    "    ax1.set_xlabel('')\n",
    "    ax1.set_title('Probplot against the normal distribution (line) ')\n",
    "    ax2 = fig.add_subplot(212)\n",
    "    prob = stats.probplot(transformed_data, dist=stats.norm, plot=ax2)\n",
    "    ax2.set_title('Probplot after ' + transformation_used + ' transformation')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: \n",
    "Try **box-cox** (available in **scipy**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate some data with noise\n",
    "raw_data = stats.loggamma.rvs(5, size=100) + 20\n",
    "weird_distr_data = [1,1,1,1,1,1,1,7]\n",
    "# apply box-cox\n",
    "transformed_data, _ = stats.boxcox(raw_data)\n",
    "# plot and compare \n",
    "plot_compare_transformations(raw_data, transformed_data, 'box-cox')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see the same effect in numbers:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example with shapiro's test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test of normal distribution with Shapiros Test')\n",
    "print('stat:', stats.shapiro(raw_data)[0],'p-value:', stats.shapiro(raw_data)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test of normal distribution with Shapiros Test')\n",
    "print('stat:', stats.shapiro(transformed_data)[0],'p-value:', stats.shapiro(transformed_data)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = ['Jarque-Bera', 'Chi^2 two-tail prob.', 'Skew', 'Kurtosis']\n",
    "test = sms.jarque_bera(raw_data)\n",
    "lzip(name, test)\n",
    "test = sms.jarque_bera(transformed_data)\n",
    "lzip(name, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to generate more data and apply other transformations, always inspecting the effect with QQ-plots and/or tests  \n",
    "\n",
    "`x = np.random.normal(0, 1, 500)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href='https://www.freepik.com/vectors/data'>Data vector created by stories - www.freepik.com</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
